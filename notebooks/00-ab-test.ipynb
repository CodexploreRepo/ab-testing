{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AB Testing\n",
    "- In A/B tests, we need to compare 2 variations so to have 2 different hypotheses: \n",
    "- **Null Hypothesis** is as follows: there is no difference between variations A and B. In other words, it posits the hypothesis that there is no statistically significant difference in the performances of variations A and B.\n",
    "\n",
    "$$H_0: \\mu_0 = \\mu_1$$\n",
    "\n",
    "- **Alternative Hypothesis** is the hypothesis where we expect the new variation to perform better. In other words, we are talking about a real difference:\n",
    "\n",
    "$$H_0: \\mu_0 \\neq \\mu_1$$\n",
    "\n",
    "- Once the hypotheses are formulated, statistical evidence is required to support them. Statistical evidence is obtained through the analysis of the collected data and the application of appropriate statistical methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.stats.api as sms\n",
    "from scipy.stats import shapiro, mannwhitneyu\n",
    "np.set_printoptions(legacy='1.25')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Case Study - I\n",
    "\n",
    "<b>Business Problem:</b> Increasing Revenue through Variant Optimization\n",
    "\n",
    "<b>Background:</b>\n",
    "\n",
    "A company launched an A/B test with two variants on its website in order to increase revenue. The test randomly assigned users to either Variant A or Variant B and tracked the income generated by each user. The experiment data is stored in an Excel file and includes user IDs, the variant they were exposed to, and the revenue brought by each user.\n",
    "\n",
    "<b>Objective:</b>\n",
    "\n",
    "The objective of the A/B test is to determine which variant (Variant A or Variant B) leads to higher revenue. By identifying the more effective variant, you aim to optimize the website design or user experience to increase overall revenue.\n",
    "\n",
    "<b>Business Questions:</b>\n",
    "\n",
    "- Which variant generated higher revenue during the A/B test?\n",
    "\n",
    "- Is the difference in revenue between the variants statistically significant?\n",
    "\n",
    "- What insights can be derived from the revenue data to optimize the website and drive revenue growth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/ab-revenue-tests.csv\")\n",
    "df = df.drop_duplicates(keep=\"first\")\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Cleaning and Analysis\n",
    "- Outlier Removals: \n",
    "    - There was an extreme increase in the Revenue value from the 99th percentile to the 100th percentile.\n",
    "    - To ensure better results in statistical tests, these extreme values should be removed from the dataset. \n",
    "    - To support this, the t-based confidence interval of the \"Revenue\" values should be observed before and after removing the outliers from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7933.000000\n",
       "mean        0.125359\n",
       "std         2.602527\n",
       "min         0.000000\n",
       "0%          0.000000\n",
       "5%          0.000000\n",
       "50%         0.000000\n",
       "95%         0.000000\n",
       "99%         2.233600\n",
       "100%      196.010000\n",
       "max       196.010000\n",
       "Name: REVENUE, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"REVENUE\"].describe([0, 0.05, 0.50, 0.95, 0.99, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for Revenue: (0.06808022416157984, 0.1826370328660264)\n"
     ]
    }
   ],
   "source": [
    "# Before outlier removal\n",
    "conf_int = sms.DescrStatsW(df['REVENUE']).tconfint_mean()\n",
    "\n",
    "print(f'95% confidence interval for Revenue: {conf_int}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0 6.0\n"
     ]
    }
   ],
   "source": [
    "class OutlierHandler():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def get_outlier_thresholds(self, df, col_name, lower_quantile=0.25, upper_quantile=0.75):\n",
    "        \"\"\"\n",
    "        Calculate the lower and upper outlier thresholds for a given variable in the dataframe.\n",
    "\n",
    "        Parameters:\n",
    "            dataframe (pandas.DataFrame): The dataframe containing the variable.\n",
    "            variable (str): The name of the variable for which outlier thresholds will be calculated.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the lower and upper outlier thresholds.\n",
    "        \"\"\"\n",
    "        quartile_1 = df[col_name].quantile(lower_quantile)\n",
    "        quartile_3 = df[col_name].quantile(upper_quantile)\n",
    "        interquantile_range = quartile_3 - quartile_1\n",
    "        up_limit = quartile_3 + 1.5 * interquantile_range\n",
    "        low_limit = quartile_1 - 1.5 * interquantile_range\n",
    "        return low_limit.round(), up_limit.round()\n",
    "\n",
    "\n",
    "    def replace_with_thresholds(self, df, col_name, low_limit, up_limit):\n",
    "        \"\"\"\n",
    "        Replace the outliers in the given variable of the dataframe with the lower and upper thresholds.\n",
    "\n",
    "        Parameters:\n",
    "            dataframe (pandas.DataFrame): The dataframe containing the variable.\n",
    "            variable (str): The name of the variable for which outliers will be replaced.\n",
    "\n",
    "        Returns:\n",
    "            None  \n",
    "        \"\"\"\n",
    "        df.loc[(df[col_name] < low_limit), col_name] = low_limit\n",
    "        df.loc[(df[col_name] > up_limit), col_name] = up_limit\n",
    "        return df\n",
    "out_handler = OutlierHandler()\n",
    "low_limit, up_limit = out_handler.get_outlier_thresholds(df, \"REVENUE\", lower_quantile=0.01, upper_quantile=0.99)       \n",
    "print(low_limit, up_limit)\n",
    "df = out_handler.replace_with_thresholds(df, \"REVENUE\", low_limit, up_limit )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for Revenue: (0.04618289998844694, 0.06783701681478008)\n"
     ]
    }
   ],
   "source": [
    "# After outlier handler\n",
    "conf_int = sms.DescrStatsW(df['REVENUE']).tconfint_mean()\n",
    "\n",
    "print(f'95% confidence interval for Revenue: {conf_int}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the statement that outliers have been replaced, and the t-based confidence interval of the Revenue values is deemed acceptable, we can proceed to the next step of the analysis. Removing or handling outliers appropriately is crucial to ensure that extreme values do not unduly influence the statistical results. With the outlier issue addressed, the data is now more robust, and we can proceed with hypothesis definitation and testing and further analysis with confidence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining the Hypothesis for the A/B Test\n",
    "\n",
    "In this section, we will define the hypothesis for the A/B test. As mentioned earlier, the A/B test aims to compare the revenue of two variations, A and B, and determine if there is a statistically significant difference between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVENUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VARIANT_NAME</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>control</th>\n",
       "      <td>0.065094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant</th>\n",
       "      <td>0.048899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               REVENUE\n",
       "VARIANT_NAME          \n",
       "control       0.065094\n",
       "variant       0.048899"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('VARIANT_NAME').agg({'REVENUE': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above results, it is evident that the revenue values of the control group are better than those of the variant group. However, at this point, we do not know if this difference is merely a result of random chance. To test this, we can define our hypotheses as follows:\n",
    "\n",
    "$$ H_0: \\text{There is no statistically significant difference between the revenue of} \\\\\n",
    "\\text{the control and variant groups.} $$\n",
    "\n",
    "$$ H_1: \\text{There is a statistically significant difference between the revenue of} \\\\\n",
    "\\text{the control and variant groups.} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Conducting the Hypothesis Test\n",
    "\n",
    "- To test the hypotheses, we will use an appropriate statistical test based on the nature of the data and assumptions. \n",
    "    - One of the assumptions is the normality assumption. To test this assumption, we will apply the **Shapiro-Wilk** test.\n",
    "- The **Shapiro-Wilk** test is a widely used test for assessing the **normality of a distribution**. It tests the null hypothesis that the data is normally distributed against the alternative hypothesis that the data does not follow a normal distribution. If the p-value obtained from the Shapiro-Wilk test is greater than the chosen significance level (typically 0.05), we will fail to reject the null hypothesis and conclude that the data can be assumed to be normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Stat = 0.0877, p-value = 0.0000\n",
      "Test Stat = 0.0992, p-value = 0.0000\n"
     ]
    }
   ],
   "source": [
    "test_stat, pvalue = shapiro(df.loc[df[\"VARIANT_NAME\"] == \"variant\", \"REVENUE\"])\n",
    "print('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))\n",
    "\n",
    "test_stat, pvalue = shapiro(df.loc[df[\"VARIANT_NAME\"] == \"control\", \"REVENUE\"])\n",
    "print('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on the results of the Shapiro-Wilk test, which produced a p-value of 0.000 for both the control and variant groups, we reject the null hypothesis of normality. Therefore, the revenue data for both groups does not follow a normal distribution.\n",
    "- As the normality assumption is violated, we will opt for a **non-parametric** test, specifically the **Mann-Whitney U** test, to compare the means of the control and variant groups. \n",
    "- The Mann-Whitney U test is suitable for data that does not meet the normality assumption and is used to assess if there is a statistically significant difference between two independent groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Stat = 7850692.0000, p-value = 0.5129\n"
     ]
    }
   ],
   "source": [
    "test_stat, pvalue = mannwhitneyu(df.loc[df[\"VARIANT_NAME\"] == \"variant\", \"REVENUE\"],\n",
    "                                 df.loc[df[\"VARIANT_NAME\"] == \"control\", \"REVENUE\"])\n",
    "\n",
    "print('Test Stat = %.4f, p-value = %.4f' % (test_stat, pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Mann-Whitney U test resulted in a p-value of 0.5129. Based on this p-value, we fail to reject the null hypothesis, indicating that there is no statistically significant difference in revenue between the two variants.\n",
    "- Regarding which variant generated higher revenue during the A/B test, the statistical test does not provide evidence of a significant distinction. Both the control and variant groups seem to perform similarly in terms of revenue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ab_testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
